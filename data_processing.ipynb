{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import networkx as nx\n",
    "from fa2_modified import ForceAtlas2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/avatar.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Dictionary to store character connections\n",
    "character_connections = {}\n",
    "# Dictionary to store connections by chapter\n",
    "chapter_connections = {}\n",
    "# Dictionary to store character connections by book\n",
    "character_connections_by_book = {}\n",
    "\n",
    "\n",
    "scene_characters = set()  # Characters in the current scene\n",
    "\n",
    "\n",
    "# Name replacements for normalization\n",
    "name_replacements = {\n",
    "    'young zuko': 'zuko',\n",
    "    'young azula': 'azula',\n",
    "    'young katara': 'katara',\n",
    "    'young sokka': 'sokka',\n",
    "    'young toph': 'toph',\n",
    "    'young aang': 'aang',\n",
    "    'king bumi': 'bumi',\n",
    "    'avatar roku': 'roku',\n",
    "    'avatar kyoshi': 'kyoshi',\n",
    "    'avatar kuruk': 'kuruk',\n",
    "    'avatar yangchen': 'yangchen',\n",
    "    'aang:': 'aang',\n",
    "    'sha-mo:': 'sha-mo',    \n",
    "}\n",
    "\n",
    "# Exclude these words from being counted as characters\n",
    "invalid_characters = {'together', 'both'}\n",
    "\n",
    "# Function to normalize character names\n",
    "def normalize_name(name):\n",
    "    # Convert to lowercase, strip spaces, and standardize\n",
    "    normalized = name.lower().strip()\n",
    "    return name_replacements.get(normalized, normalized)\n",
    "\n",
    "# Function to split multiple characters and normalize their names\n",
    "def split_characters(character):\n",
    "    # Replace \"Team Avatar\" with its members\n",
    "    if 'team avatar' in character.lower():\n",
    "        return ['sokka', 'katara', 'aang', 'toph']\n",
    "    \n",
    "    # Use regex to split by commas or 'and', and normalize each name\n",
    "    names = [normalize_name(name) for name in re.split(r',|\\band\\b', character)]\n",
    "    # Filter out invalid characters\n",
    "    return [name for name in names if name not in invalid_characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                pair  count\n",
      "0    (katara, sokka)    386\n",
      "1       (iroh, zuko)    112\n",
      "2     (aang, katara)    411\n",
      "3      (aang, sokka)    409\n",
      "4      (aang, kanna)      3\n",
      "..               ...    ...\n",
      "963     (bumi, iroh)      1\n",
      "964    (iroh, pakku)      1\n",
      "965     (ozai, suki)      1\n",
      "966      (iroh, mai)      1\n",
      "967      (mai, toph)      1\n",
      "\n",
      "[968 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each row to detect scene boundaries\n",
    "for _, row in df.iterrows():\n",
    "    # Check if the row indicates a new scene\n",
    "    if row['character'] == 'Scene Description':\n",
    "        # Create character pairs for the completed scene\n",
    "        pairs = combinations(scene_characters, 2)\n",
    "        for pair in pairs:\n",
    "            pair = tuple(sorted(pair))  # Ensure consistent ordering\n",
    "            if pair in character_connections:\n",
    "                character_connections[pair] += 1\n",
    "            else:\n",
    "                character_connections[pair] = 1\n",
    "\n",
    "        # Reset the scene_characters for the next scene\n",
    "        scene_characters = set()\n",
    "    else:\n",
    "        # Check for multiple characters and add each to the current scene\n",
    "        characters = split_characters(row['character'])\n",
    "        scene_characters.update(characters)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "connections_df = pd.DataFrame(list(character_connections.items()), columns=['pair', 'count'])\n",
    "\n",
    "# Display the connections\n",
    "print(connections_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "connections_df.to_csv('character_connections.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       book                               chapter  \\\n",
      "0     Earth                      Appa's Lost Days   \n",
      "1     Earth                      Appa's Lost Days   \n",
      "2     Earth                      Appa's Lost Days   \n",
      "3     Earth                      Appa's Lost Days   \n",
      "4     Earth                      Appa's Lost Days   \n",
      "...     ...                                   ...   \n",
      "1594  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "1595  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "1596  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "1597  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "1598  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "\n",
      "                                pair  count  \n",
      "0                   (ghashiun, toph)      1  \n",
      "1          (ghashiun, sandbender #2)      1  \n",
      "2          (ghashiun, sandbender #1)      1  \n",
      "3     (sandbender #1, sandbender #2)      1  \n",
      "4            (ghashiun, merchant #1)      1  \n",
      "...                              ...    ...  \n",
      "1594                    (aang, roku)      2  \n",
      "1595                    (roku, shyu)      1  \n",
      "1596                    (shyu, zhao)      1  \n",
      "1597                   (roku, sokka)      1  \n",
      "1598                  (katara, roku)      1  \n",
      "\n",
      "[1599 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each chapter\n",
    "for (book, chapter), chapter_group in df.groupby(['book', 'chapter']):\n",
    "    scene_characters = set()  # Characters in the current scene\n",
    "    chapter_key = (book, chapter)  # Use book and chapter as a key\n",
    "    chapter_connections[chapter_key] = {}\n",
    "\n",
    "    # Iterate over rows within the chapter\n",
    "    for _, row in chapter_group.iterrows():\n",
    "        if row['character'] == 'Scene Description':\n",
    "            # Create character pairs for the completed scene\n",
    "            pairs = combinations(scene_characters, 2)\n",
    "            for pair in pairs:\n",
    "                pair = tuple(sorted(pair))\n",
    "                if pair in chapter_connections[chapter_key]:\n",
    "                    chapter_connections[chapter_key][pair] += 1\n",
    "                else:\n",
    "                    chapter_connections[chapter_key][pair] = 1\n",
    "\n",
    "            # Reset the scene_characters for the next scene\n",
    "            scene_characters = set()\n",
    "        else:\n",
    "            # Check for multiple characters and add each to the current scene\n",
    "            characters = split_characters(row['character'])\n",
    "            scene_characters.update(characters)\n",
    "\n",
    "# Convert chapter-based connections to a DataFrame\n",
    "chapter_connections_list = []\n",
    "for (book, chapter), connections in chapter_connections.items():\n",
    "    for pair, count in connections.items():\n",
    "        chapter_connections_list.append({\n",
    "            'book': book,\n",
    "            'chapter': chapter,\n",
    "            'pair': pair,\n",
    "            'count': count\n",
    "        })\n",
    "\n",
    "chapter_connections_df = pd.DataFrame(chapter_connections_list)\n",
    "\n",
    "# Display the connections\n",
    "print(chapter_connections_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "chapter_connections_df.to_csv('chapter_character_connections.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       book                   pair  count\n",
      "0     Earth         (aang, katara)    113\n",
      "1     Earth          (aang, pakku)      1\n",
      "2     Earth        (katara, pakku)      1\n",
      "3     Earth           (iroh, zuko)     55\n",
      "4     Earth       (azula, captain)      2\n",
      "...     ...                    ...    ...\n",
      "1071  Water            (yue, zuko)      1\n",
      "1072  Water  (aang, baboon spirit)      1\n",
      "1073  Water            (aang, koh)      3\n",
      "1074  Water            (yue, zhao)      1\n",
      "1075  Water            (iroh, yue)      1\n",
      "\n",
      "[1076 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each book\n",
    "for book, book_group in df.groupby('book'):\n",
    "    scene_characters = set()  # Characters in the current scene\n",
    "    character_connections = {}  # Connections for this book\n",
    "\n",
    "    # Iterate over each row within the book\n",
    "    for _, row in book_group.iterrows():\n",
    "        if row['character'] == 'Scene Description':\n",
    "            # Create character pairs for the completed scene\n",
    "            pairs = combinations(scene_characters, 2)\n",
    "            for pair in pairs:\n",
    "                pair = tuple(sorted(pair))  # Ensure consistent ordering\n",
    "                if pair in character_connections:\n",
    "                    character_connections[pair] += 1\n",
    "                else:\n",
    "                    character_connections[pair] = 1\n",
    "\n",
    "            # Reset the scene_characters for the next scene\n",
    "            scene_characters = set()\n",
    "        else:\n",
    "            # Add characters to the current scene\n",
    "            characters = split_characters(row['character'])\n",
    "            scene_characters.update(characters)\n",
    "\n",
    "    # Store connections for this book\n",
    "    character_connections_by_book[book] = character_connections\n",
    "\n",
    "# Convert connections_by_book to a DataFrame\n",
    "book_connections = []\n",
    "\n",
    "for book, connections in character_connections_by_book.items():\n",
    "    for pair, count in connections.items():\n",
    "        book_connections.append({'book': book, 'pair': pair, 'count': count})\n",
    "\n",
    "book_connections_df = pd.DataFrame(book_connections)\n",
    "\n",
    "# Display the book-based connections\n",
    "print(book_connections_df)\n",
    "\n",
    "# Save to CSV for further analysis\n",
    "book_connections_df.to_csv('character_connections_by_book.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            character  dialogue_count  scene_count  episode_count  \\\n",
      "0              katara           15067          875             59   \n",
      "1               sokka           18392         1009             59   \n",
      "2                zuko            9277          466             47   \n",
      "3                iroh            5276          198             36   \n",
      "4                aang           17947         1120             60   \n",
      "..                ...             ...          ...            ...   \n",
      "345          yangchen              90            1              1   \n",
      "346       lion turtle              78            4              2   \n",
      "347  banished servant              33            1              1   \n",
      "348    head of dai li              28            1              1   \n",
      "349           qin lee              10            1              1   \n",
      "\n",
      "           arc_presence  average_sentiment  \n",
      "0    Fire, Water, Earth           0.059311  \n",
      "1    Fire, Water, Earth           0.058501  \n",
      "2    Fire, Water, Earth           0.030078  \n",
      "3    Fire, Water, Earth           0.154453  \n",
      "4    Fire, Water, Earth           0.073002  \n",
      "..                  ...                ...  \n",
      "345                Fire           0.167857  \n",
      "346                Fire           0.194444  \n",
      "347                Fire          -0.050000  \n",
      "348                Fire           0.017143  \n",
      "349                Fire           0.000000  \n",
      "\n",
      "[350 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the attributes dictionary\n",
    "character_attributes = {}\n",
    "\n",
    "# Sentiment Analysis Function\n",
    "def calculate_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity if pd.notna(text) else 0\n",
    "\n",
    "# Iterate through each row\n",
    "for _, row in df.iterrows():\n",
    "    if row['character'] == 'Scene Description':  # New scene boundary\n",
    "        # Increment scene counts for all characters in the scene\n",
    "        for character in scene_characters:\n",
    "            if character in character_attributes:\n",
    "                character_attributes[character]['scene_count'] += 1\n",
    "        scene_characters = set()  # Reset for the next scene\n",
    "    else:\n",
    "        # Track characters in the current scene\n",
    "        characters = split_characters(row['character'])\n",
    "        scene_characters.update(characters)\n",
    "\n",
    "        for character in characters:\n",
    "            if character not in character_attributes:\n",
    "                character_attributes[character] = {\n",
    "                    'dialogue_count': 0,\n",
    "                    'scene_count': 0,\n",
    "                    'episode_count': set(),\n",
    "                    'arc_presence': set(),\n",
    "                    'sentiment_sum': 0,\n",
    "                    'sentiment_count': 0\n",
    "                }\n",
    "\n",
    "            # Increment dialogue count by the number of words in the dialogue\n",
    "            dialogue = row['character_words']\n",
    "            word_count = len(dialogue.split()) if pd.notna(dialogue) else 0\n",
    "            character_attributes[character]['dialogue_count'] += word_count\n",
    "\n",
    "            # Track episodes and arcs\n",
    "            character_attributes[character]['episode_count'].add((row['book'], row['chapter']))\n",
    "            character_attributes[character]['arc_presence'].add(row['book'])\n",
    "\n",
    "            # Update sentiment analysis\n",
    "            sentiment = calculate_sentiment(dialogue)\n",
    "            character_attributes[character]['sentiment_sum'] += sentiment\n",
    "            character_attributes[character]['sentiment_count'] += 1\n",
    "\n",
    "# Process the attributes into a DataFrame\n",
    "processed_attributes = []\n",
    "for character, attributes in character_attributes.items():\n",
    "    processed_attributes.append({\n",
    "        'character': character,\n",
    "        'dialogue_count': attributes['dialogue_count'],\n",
    "        'scene_count': attributes['scene_count'],\n",
    "        'episode_count': len(attributes['episode_count']),\n",
    "        'arc_presence': ', '.join(attributes['arc_presence']),\n",
    "        'average_sentiment': (attributes['sentiment_sum'] / attributes['sentiment_count']) if attributes['sentiment_count'] > 0 else None\n",
    "    })\n",
    "\n",
    "character_df = pd.DataFrame(processed_attributes)\n",
    "\n",
    "# Save to CSV\n",
    "character_df.to_csv('character_attributes.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(character_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
