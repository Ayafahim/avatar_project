{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import networkx as nx\n",
    "from fa2_modified import ForceAtlas2\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/avatar.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Dictionary to store character connections\n",
    "character_connections = {}\n",
    "# Dictionary to store connections by chapter\n",
    "chapter_connections = {}\n",
    "# Dictionary to store character connections by book\n",
    "character_connections_by_book = {}\n",
    "\n",
    "\n",
    "scene_characters = set()  # Characters in the current scene\n",
    "\n",
    "\n",
    "# Name replacements for normalization\n",
    "name_replacements = {\n",
    "    'young zuko': 'zuko',\n",
    "    'young azula': 'azula',\n",
    "    'young katara': 'katara',\n",
    "    'young sokka': 'sokka',\n",
    "    'young toph': 'toph',\n",
    "    'young aang': 'aang',\n",
    "    'king bumi': 'bumi',\n",
    "    'avatar roku': 'roku',\n",
    "    'avatar kyoshi': 'kyoshi',\n",
    "    'avatar kuruk': 'kuruk',\n",
    "    'avatar yangchen': 'yangchen',\n",
    "    'aang:': 'aang',\n",
    "    'sha-mo:': 'sha-mo',    \n",
    "}\n",
    "\n",
    "# Exclude these words from being counted as characters\n",
    "invalid_characters = {'together', 'both'}\n",
    "\n",
    "# Function to normalize character names\n",
    "def normalize_name(name):\n",
    "    # Convert to lowercase, strip spaces, and standardize\n",
    "    normalized = name.lower().strip()\n",
    "    return name_replacements.get(normalized, normalized)\n",
    "\n",
    "# Function to split multiple characters and normalize their names\n",
    "def split_characters(character):\n",
    "    # Replace \"Team Avatar\" with its members\n",
    "    if 'team avatar' in character.lower():\n",
    "        return ['sokka', 'katara', 'aang', 'toph']\n",
    "    \n",
    "    # Use regex to split by commas or 'and', and normalize each name\n",
    "    names = [normalize_name(name) for name in re.split(r',|\\band\\b', character)]\n",
    "    # Filter out invalid characters\n",
    "    return [name for name in names if name not in invalid_characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                pair  count\n",
      "0    (katara, sokka)    386\n",
      "1       (iroh, zuko)    112\n",
      "2     (aang, katara)    411\n",
      "3      (aang, sokka)    409\n",
      "4      (aang, kanna)      3\n",
      "..               ...    ...\n",
      "963     (bumi, iroh)      1\n",
      "964    (iroh, pakku)      1\n",
      "965     (ozai, suki)      1\n",
      "966      (mai, toph)      1\n",
      "967      (iroh, mai)      1\n",
      "\n",
      "[968 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each row to detect scene boundaries\n",
    "for _, row in df.iterrows():\n",
    "    # Check if the row indicates a new scene\n",
    "    if row['character'] == 'Scene Description':\n",
    "        # Create character pairs for the completed scene\n",
    "        pairs = combinations(scene_characters, 2)\n",
    "        for pair in pairs:\n",
    "            pair = tuple(sorted(pair))  # Ensure consistent ordering\n",
    "            if pair in character_connections:\n",
    "                character_connections[pair] += 1\n",
    "            else:\n",
    "                character_connections[pair] = 1\n",
    "\n",
    "        # Reset the scene_characters for the next scene\n",
    "        scene_characters = set()\n",
    "    else:\n",
    "        # Check for multiple characters and add each to the current scene\n",
    "        characters = split_characters(row['character'])\n",
    "        scene_characters.update(characters)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "connections_df = pd.DataFrame(list(character_connections.items()), columns=['pair', 'count'])\n",
    "\n",
    "# Display the connections\n",
    "print(connections_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "connections_df.to_csv('character_connections.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       book                               chapter  \\\n",
      "0     Earth                      Appa's Lost Days   \n",
      "1     Earth                      Appa's Lost Days   \n",
      "2     Earth                      Appa's Lost Days   \n",
      "3     Earth                      Appa's Lost Days   \n",
      "4     Earth                      Appa's Lost Days   \n",
      "...     ...                                   ...   \n",
      "1594  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "1595  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "1596  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "1597  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "1598  Water  Winter Solstice, Part 2: Avatar Roku   \n",
      "\n",
      "                                pair  count  \n",
      "0                   (ghashiun, toph)      1  \n",
      "1          (ghashiun, sandbender #1)      1  \n",
      "2          (ghashiun, sandbender #2)      1  \n",
      "3     (sandbender #1, sandbender #2)      1  \n",
      "4            (ghashiun, merchant #1)      1  \n",
      "...                              ...    ...  \n",
      "1594         (great fire sage, roku)      1  \n",
      "1595                    (roku, shyu)      1  \n",
      "1596                    (roku, zuko)      1  \n",
      "1597                  (katara, roku)      1  \n",
      "1598                   (roku, sokka)      1  \n",
      "\n",
      "[1599 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each chapter\n",
    "for (book, chapter), chapter_group in df.groupby(['book', 'chapter']):\n",
    "    scene_characters = set()  # Characters in the current scene\n",
    "    chapter_key = (book, chapter)  # Use book and chapter as a key\n",
    "    chapter_connections[chapter_key] = {}\n",
    "\n",
    "    # Iterate over rows within the chapter\n",
    "    for _, row in chapter_group.iterrows():\n",
    "        if row['character'] == 'Scene Description':\n",
    "            # Create character pairs for the completed scene\n",
    "            pairs = combinations(scene_characters, 2)\n",
    "            for pair in pairs:\n",
    "                pair = tuple(sorted(pair))\n",
    "                if pair in chapter_connections[chapter_key]:\n",
    "                    chapter_connections[chapter_key][pair] += 1\n",
    "                else:\n",
    "                    chapter_connections[chapter_key][pair] = 1\n",
    "\n",
    "            # Reset the scene_characters for the next scene\n",
    "            scene_characters = set()\n",
    "        else:\n",
    "            # Check for multiple characters and add each to the current scene\n",
    "            characters = split_characters(row['character'])\n",
    "            scene_characters.update(characters)\n",
    "\n",
    "# Convert chapter-based connections to a DataFrame\n",
    "chapter_connections_list = []\n",
    "for (book, chapter), connections in chapter_connections.items():\n",
    "    for pair, count in connections.items():\n",
    "        chapter_connections_list.append({\n",
    "            'book': book,\n",
    "            'chapter': chapter,\n",
    "            'pair': pair,\n",
    "            'count': count\n",
    "        })\n",
    "\n",
    "chapter_connections_df = pd.DataFrame(chapter_connections_list)\n",
    "\n",
    "# Display the connections\n",
    "print(chapter_connections_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "chapter_connections_df.to_csv('chapter_character_connections.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       book                   pair  count\n",
      "0     Earth         (aang, katara)    113\n",
      "1     Earth        (katara, pakku)      1\n",
      "2     Earth          (aang, pakku)      1\n",
      "3     Earth           (iroh, zuko)     55\n",
      "4     Earth       (azula, captain)      2\n",
      "...     ...                    ...    ...\n",
      "1071  Water            (yue, zuko)      1\n",
      "1072  Water  (aang, baboon spirit)      1\n",
      "1073  Water            (aang, koh)      3\n",
      "1074  Water            (yue, zhao)      1\n",
      "1075  Water            (iroh, yue)      1\n",
      "\n",
      "[1076 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each book\n",
    "for book, book_group in df.groupby('book'):\n",
    "    scene_characters = set()  # Characters in the current scene\n",
    "    character_connections = {}  # Connections for this book\n",
    "\n",
    "    # Iterate over each row within the book\n",
    "    for _, row in book_group.iterrows():\n",
    "        if row['character'] == 'Scene Description':\n",
    "            # Create character pairs for the completed scene\n",
    "            pairs = combinations(scene_characters, 2)\n",
    "            for pair in pairs:\n",
    "                pair = tuple(sorted(pair))  # Ensure consistent ordering\n",
    "                if pair in character_connections:\n",
    "                    character_connections[pair] += 1\n",
    "                else:\n",
    "                    character_connections[pair] = 1\n",
    "\n",
    "            # Reset the scene_characters for the next scene\n",
    "            scene_characters = set()\n",
    "        else:\n",
    "            # Add characters to the current scene\n",
    "            characters = split_characters(row['character'])\n",
    "            scene_characters.update(characters)\n",
    "\n",
    "    # Store connections for this book\n",
    "    character_connections_by_book[book] = character_connections\n",
    "\n",
    "# Convert connections_by_book to a DataFrame\n",
    "book_connections = []\n",
    "\n",
    "for book, connections in character_connections_by_book.items():\n",
    "    for pair, count in connections.items():\n",
    "        book_connections.append({'book': book, 'pair': pair, 'count': count})\n",
    "\n",
    "book_connections_df = pd.DataFrame(book_connections)\n",
    "\n",
    "# Display the book-based connections\n",
    "print(book_connections_df)\n",
    "\n",
    "# Save to CSV for further analysis\n",
    "book_connections_df.to_csv('character_connections_by_book.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       book                   pair  count  \\\n",
      "0     Earth         (aang, katara)    113   \n",
      "1     Earth        (katara, pakku)      1   \n",
      "2     Earth          (aang, pakku)      1   \n",
      "3     Earth           (iroh, zuko)     55   \n",
      "4     Earth       (azula, captain)      2   \n",
      "...     ...                    ...    ...   \n",
      "1071  Water            (yue, zuko)      1   \n",
      "1072  Water  (aang, baboon spirit)      1   \n",
      "1073  Water            (aang, koh)      3   \n",
      "1074  Water            (yue, zhao)      1   \n",
      "1075  Water            (iroh, yue)      1   \n",
      "\n",
      "      average_sentiment_between_characters  \n",
      "0                                -0.096103  \n",
      "1                                 0.904363  \n",
      "2                                 0.904363  \n",
      "3                                -0.009508  \n",
      "4                                -0.074584  \n",
      "...                                    ...  \n",
      "1071                              0.213319  \n",
      "1072                              0.744977  \n",
      "1073                              0.259550  \n",
      "1074                             -0.159776  \n",
      "1075                              0.631177  \n",
      "\n",
      "[1076 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "# Load the BERT sentiment analysis model\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", framework=\"pt\")\n",
    "\n",
    "# Function to calculate sentiment using BERT\n",
    "def calculate_bert_sentiment(text, positive_bias=1.5, negative_bias=1.5):\n",
    "    \"\"\"\n",
    "    Calculate sentiment using a BERT model and apply bias.\n",
    "    Positive sentiments are amplified by `positive_bias`.\n",
    "    Negative sentiments are amplified by `negative_bias`.\n",
    "    \"\"\"\n",
    "    if pd.notna(text) and text.strip():\n",
    "        result = sentiment_analyzer(text[:512])[0]  # Analyze up to 512 characters\n",
    "        label = result[\"label\"]\n",
    "        score = float(result[\"score\"])\n",
    "\n",
    "        if \"POSITIVE\" in label.upper():\n",
    "            return score * positive_bias\n",
    "        elif \"NEGATIVE\" in label.upper():\n",
    "            return -score * negative_bias\n",
    "        return 0  # Neutral sentiment\n",
    "    return 0  # No valid text\n",
    "\n",
    "# Iterate over each book\n",
    "character_connections_by_book = {}\n",
    "for book, book_group in df.groupby('book'):\n",
    "    scene_characters = set()  # Characters in the current scene\n",
    "    scene_sentiment_sum = 0  # Total sentiment for the current scene\n",
    "    total_sentences = 0  # Count of sentences for normalization\n",
    "    character_connections = {}  # Connections for this book\n",
    "\n",
    "    # Iterate over each row within the book\n",
    "    for _, row in book_group.iterrows():\n",
    "        if row['character'] == 'Scene Description':\n",
    "            if total_sentences > 0:\n",
    "                # Calculate average sentiment for the completed scene\n",
    "                average_scene_sentiment = scene_sentiment_sum / total_sentences\n",
    "            else:\n",
    "                # No character dialogue, sentiment is neutral\n",
    "                average_scene_sentiment = 0\n",
    "\n",
    "            # Create character pairs for the completed scene\n",
    "            pairs = combinations(scene_characters, 2)\n",
    "            for pair in pairs:\n",
    "                pair = tuple(sorted(pair))  # Ensure consistent ordering\n",
    "                if pair in character_connections:\n",
    "                    # Update weight and average sentiment\n",
    "                    character_connections[pair]['count'] += 1\n",
    "                    character_connections[pair]['sentiment'] += average_scene_sentiment\n",
    "                else:\n",
    "                    character_connections[pair] = {\n",
    "                        'count': 1,\n",
    "                        'sentiment': average_scene_sentiment\n",
    "                    }\n",
    "\n",
    "            # Reset the scene_characters and sentiment trackers for the next scene\n",
    "            scene_characters = set()\n",
    "            scene_sentiment_sum = 0\n",
    "            total_sentences = 0\n",
    "        else:\n",
    "            # Add characters to the current scene\n",
    "            characters = split_characters(row['character'])\n",
    "            scene_characters.update(characters)\n",
    "\n",
    "            # Calculate BERT sentiment for this character's full text if available\n",
    "            character_text = row['character_words']\n",
    "            if pd.notna(character_text) and character_text.strip():\n",
    "                sentiment = calculate_bert_sentiment(character_text, positive_bias=1.5, negative_bias=1.5)\n",
    "                scene_sentiment_sum += sentiment\n",
    "                total_sentences += 1\n",
    "\n",
    "    # Normalize sentiment scores (average over the number of scenes)\n",
    "    for pair in character_connections:\n",
    "        connection = character_connections[pair]\n",
    "        connection['sentiment'] /= connection['count']\n",
    "\n",
    "    # Store connections for this book\n",
    "    character_connections_by_book[book] = character_connections\n",
    "\n",
    "# Convert connections_by_book to a DataFrame\n",
    "book_connections = []\n",
    "\n",
    "for book, connections in character_connections_by_book.items():\n",
    "    for pair, data in connections.items():\n",
    "        book_connections.append({\n",
    "            'book': book,\n",
    "            'pair': pair,\n",
    "            'count': data['count'],\n",
    "            'average_sentiment_between_characters': data['sentiment']\n",
    "        })\n",
    "\n",
    "book_connections_df = pd.DataFrame(book_connections)\n",
    "\n",
    "# Display the book-based connections with sentiment\n",
    "print(book_connections_df)\n",
    "\n",
    "# Save to CSV for further analysis\n",
    "book_connections_df.to_csv('character_connections_by_book_with_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            character  dialogue_count  scene_count  episode_count  \\\n",
      "0              katara           15067          875             59   \n",
      "1               sokka           18392         1009             59   \n",
      "2                zuko            9277          466             47   \n",
      "3                iroh            5276          198             36   \n",
      "4                aang           17947         1120             60   \n",
      "..                ...             ...          ...            ...   \n",
      "345          yangchen              90            1              1   \n",
      "346       lion turtle              78            4              2   \n",
      "347  banished servant              33            1              1   \n",
      "348    head of dai li              28            1              1   \n",
      "349           qin lee              10            1              1   \n",
      "\n",
      "           arc_presence  positive_proportion  negative_proportion  \\\n",
      "0    Earth, Fire, Water             0.405057             0.594943   \n",
      "1    Earth, Fire, Water             0.385657             0.614343   \n",
      "2    Earth, Fire, Water             0.430958             0.569042   \n",
      "3    Earth, Fire, Water             0.591547             0.408453   \n",
      "4    Earth, Fire, Water             0.453112             0.546888   \n",
      "..                  ...                  ...                  ...   \n",
      "345                Fire             0.711111             0.288889   \n",
      "346                Fire             0.782051             0.217949   \n",
      "347                Fire             0.393939             0.606061   \n",
      "348                Fire             0.571429             0.428571   \n",
      "349                Fire             1.000000             0.000000   \n",
      "\n",
      "     neutral_proportion  \n",
      "0                   0.0  \n",
      "1                   0.0  \n",
      "2                   0.0  \n",
      "3                   0.0  \n",
      "4                   0.0  \n",
      "..                  ...  \n",
      "345                 0.0  \n",
      "346                 0.0  \n",
      "347                 0.0  \n",
      "348                 0.0  \n",
      "349                 0.0  \n",
      "\n",
      "[350 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", \n",
    "                              model=\"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "                              framework=\"pt\")\n",
    "\n",
    "# Prepare the attributes dictionary\n",
    "character_attributes = {}\n",
    "\n",
    "# Keep track of the current arc (book) and scene characters\n",
    "current_book = None\n",
    "scene_characters = set()\n",
    "\n",
    "# Sentiment Analysis Function using BERT\n",
    "def calculate_sentiment(text):\n",
    "    if pd.notna(text) and text.strip():\n",
    "        # Analyze sentiment using the BERT pipeline\n",
    "        result = sentiment_analyzer(text[:512])  # Truncate to 512 tokens for BERT\n",
    "        label = result[0]['label']\n",
    "        # Map BERT labels to categories\n",
    "        if \"positive\" in label.lower():\n",
    "            return \"positive\"\n",
    "        elif \"negative\" in label.lower():\n",
    "            return \"negative\"\n",
    "        else:\n",
    "            return \"neutral\"\n",
    "    return \"neutral\"\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notna(row['book']):\n",
    "        current_book = row['book']\n",
    "\n",
    "    if row['character'] == 'Scene Description':\n",
    "        # At the end of the scene, increment scene counts for all characters in that scene\n",
    "        for character in scene_characters:\n",
    "            if character in character_attributes:\n",
    "                character_attributes[character]['scene_count'] += 1\n",
    "        scene_characters = set()  # Reset for the next scene\n",
    "    else:\n",
    "        # Track characters in the current scene\n",
    "        characters = split_characters(row['character'])\n",
    "        scene_characters.update(characters)\n",
    "\n",
    "        for character in characters:\n",
    "            if character not in character_attributes:\n",
    "                character_attributes[character] = {\n",
    "                    'dialogue_count': 0,\n",
    "                    'scene_count': 0,\n",
    "                    'episode_count': set(),\n",
    "                    'arc_presence': set(),\n",
    "                    'positive_dialogue': 0,\n",
    "                    'negative_dialogue': 0,\n",
    "                    'neutral_dialogue': 0\n",
    "                }\n",
    "\n",
    "            # Increment dialogue count by the number of words in the dialogue\n",
    "            dialogue = row['character_words']\n",
    "            word_count = len(dialogue.split()) if pd.notna(dialogue) else 0\n",
    "            character_attributes[character]['dialogue_count'] += word_count\n",
    "\n",
    "            # Track episodes\n",
    "            character_attributes[character]['episode_count'].add((row['book'], row['chapter']))\n",
    "\n",
    "            # Track arc presence if there's a known current_book\n",
    "            if current_book is not None:\n",
    "                character_attributes[character]['arc_presence'].add(current_book)\n",
    "\n",
    "            # Update sentiment analysis\n",
    "            sentiment_category = calculate_sentiment(dialogue)\n",
    "            if sentiment_category == \"positive\":\n",
    "                character_attributes[character]['positive_dialogue'] += word_count\n",
    "            elif sentiment_category == \"negative\":\n",
    "                character_attributes[character]['negative_dialogue'] += word_count\n",
    "            else:\n",
    "                character_attributes[character]['neutral_dialogue'] += word_count\n",
    "\n",
    "# Manually update Momo and Appa to appear in all arcs\n",
    "# First, find all arcs (books) present in the DataFrame\n",
    "all_arcs = set(df['book'].dropna())\n",
    "\n",
    "for character_name in ['momo', 'appa']:\n",
    "    if character_name in character_attributes:\n",
    "        character_attributes[character_name]['arc_presence'] = all_arcs\n",
    "\n",
    "# Process the attributes into a DataFrame\n",
    "processed_attributes = []\n",
    "for character, attributes in character_attributes.items():\n",
    "    total_dialogue = attributes['dialogue_count']\n",
    "    processed_attributes.append({\n",
    "        'character': character,\n",
    "        'dialogue_count': total_dialogue,\n",
    "        'scene_count': attributes['scene_count'],\n",
    "        'episode_count': len(attributes['episode_count']),\n",
    "        'arc_presence': ', '.join(sorted(attributes['arc_presence'])),\n",
    "        'positive_proportion': (attributes['positive_dialogue'] / total_dialogue) if total_dialogue > 0 else 0,\n",
    "        'negative_proportion': (attributes['negative_dialogue'] / total_dialogue) if total_dialogue > 0 else 0,\n",
    "        'neutral_proportion': (attributes['neutral_dialogue'] / total_dialogue) if total_dialogue > 0 else 0\n",
    "    })\n",
    "\n",
    "character_df = pd.DataFrame(processed_attributes)\n",
    "\n",
    "# Save to CSV\n",
    "character_df.to_csv('character_attributes.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(character_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       arc       character  dialogue_count  scene_count  episode_count  \\\n",
      "0    Water          katara            6275          368             20   \n",
      "1    Water           sokka            5980          374             20   \n",
      "2    Water            zuko            1773          122             13   \n",
      "3    Water            iroh            1814           85             13   \n",
      "4    Water            aang            7810          508             20   \n",
      "..     ...             ...             ...          ...            ...   \n",
      "428   Fire  head of dai li              28            1              1   \n",
      "429   Fire         qin lee              10            1              1   \n",
      "430   Fire        engineer              30            2              1   \n",
      "431   Fire     crew member              12            1              1   \n",
      "432   Fire            ursa              45            1              1   \n",
      "\n",
      "     positive_proportion  negative_proportion  neutral_proportion  \n",
      "0               0.409084             0.590916                 0.0  \n",
      "1               0.384448             0.615552                 0.0  \n",
      "2               0.441060             0.558940                 0.0  \n",
      "3               0.550165             0.449835                 0.0  \n",
      "4               0.487068             0.512932                 0.0  \n",
      "..                   ...                  ...                 ...  \n",
      "428             0.571429             0.428571                 0.0  \n",
      "429             1.000000             0.000000                 0.0  \n",
      "430             0.733333             0.266667                 0.0  \n",
      "431             1.000000             0.000000                 0.0  \n",
      "432             0.555556             0.444444                 0.0  \n",
      "\n",
      "[433 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", \n",
    "                              model=\"distilbert-base-uncased-finetuned-sst-2-english\", \n",
    "                              framework=\"pt\")\n",
    "\n",
    "# Prepare the attributes dictionary\n",
    "character_attributes_by_arc = {}\n",
    "\n",
    "# Keep track of the current arc (book) and scene characters\n",
    "current_book = None\n",
    "scene_characters = set()\n",
    "\n",
    "# Sentiment Analysis Function using BERT\n",
    "def calculate_sentiment(text):\n",
    "    if pd.notna(text) and text.strip():\n",
    "        # Analyze sentiment using the BERT pipeline\n",
    "        result = sentiment_analyzer(text[:512])  # Truncate to 512 tokens for BERT\n",
    "        label = result[0]['label']\n",
    "        # Map BERT labels to categories\n",
    "        if \"positive\" in label.lower():\n",
    "            return \"positive\"\n",
    "        elif \"negative\" in label.lower():\n",
    "            return \"negative\"\n",
    "        else:\n",
    "            return \"neutral\"\n",
    "    return \"neutral\"\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notna(row['book']):\n",
    "        current_book = row['book']  # Update the current book (arc)\n",
    "\n",
    "    if row['character'] == 'Scene Description':\n",
    "        # At the end of the scene, increment scene counts for all characters in that scene\n",
    "        for character in scene_characters:\n",
    "            if character in character_attributes_by_arc[current_book]:\n",
    "                character_attributes_by_arc[current_book][character]['scene_count'] += 1\n",
    "        scene_characters = set()  # Reset for the next scene\n",
    "    else:\n",
    "        # Track characters in the current scene\n",
    "        characters = split_characters(row['character'])\n",
    "        scene_characters.update(characters)\n",
    "\n",
    "        for character in characters:\n",
    "            # Initialize character data for this arc if not already done\n",
    "            if current_book not in character_attributes_by_arc:\n",
    "                character_attributes_by_arc[current_book] = {}\n",
    "            if character not in character_attributes_by_arc[current_book]:\n",
    "                character_attributes_by_arc[current_book][character] = {\n",
    "                    'dialogue_count': 0,\n",
    "                    'scene_count': 0,\n",
    "                    'episode_count': set(),\n",
    "                    'positive_dialogue': 0,\n",
    "                    'negative_dialogue': 0,\n",
    "                    'neutral_dialogue': 0\n",
    "                }\n",
    "\n",
    "            # Increment dialogue count by the number of words in the dialogue\n",
    "            dialogue = row['character_words']\n",
    "            word_count = len(dialogue.split()) if pd.notna(dialogue) else 0\n",
    "            character_attributes_by_arc[current_book][character]['dialogue_count'] += word_count\n",
    "\n",
    "            # Track episodes\n",
    "            character_attributes_by_arc[current_book][character]['episode_count'].add(row['chapter'])\n",
    "\n",
    "            # Update sentiment analysis\n",
    "            sentiment_category = calculate_sentiment(dialogue)\n",
    "            if sentiment_category == \"positive\":\n",
    "                character_attributes_by_arc[current_book][character]['positive_dialogue'] += word_count\n",
    "            elif sentiment_category == \"negative\":\n",
    "                character_attributes_by_arc[current_book][character]['negative_dialogue'] += word_count\n",
    "            else:\n",
    "                character_attributes_by_arc[current_book][character]['neutral_dialogue'] += word_count\n",
    "\n",
    "# Manually update Momo and Appa to appear in all arcs\n",
    "# First, find all arcs (books) present in the DataFrame\n",
    "all_arcs = set(df['book'].dropna())\n",
    "\n",
    "for arc in all_arcs:\n",
    "    if arc not in character_attributes_by_arc:\n",
    "        character_attributes_by_arc[arc] = {}\n",
    "    for character_name in ['momo', 'appa']:\n",
    "        if character_name not in character_attributes_by_arc[arc]:\n",
    "            character_attributes_by_arc[arc][character_name] = {\n",
    "                'dialogue_count': 0,\n",
    "                'scene_count': 0,\n",
    "                'episode_count': set(),\n",
    "                'positive_dialogue': 0,\n",
    "                'negative_dialogue': 0,\n",
    "                'neutral_dialogue': 0\n",
    "            }\n",
    "\n",
    "# Process the attributes into a DataFrame per arc\n",
    "processed_data = []\n",
    "\n",
    "for arc, characters in character_attributes_by_arc.items():\n",
    "    for character, attributes in characters.items():\n",
    "        total_dialogue = attributes['dialogue_count']\n",
    "        processed_data.append({\n",
    "            'arc': arc,\n",
    "            'character': character,\n",
    "            'dialogue_count': total_dialogue,\n",
    "            'scene_count': attributes['scene_count'],\n",
    "            'episode_count': len(attributes['episode_count']),\n",
    "            'positive_proportion': (attributes['positive_dialogue'] / total_dialogue) if total_dialogue > 0 else 0,\n",
    "            'negative_proportion': (attributes['negative_dialogue'] / total_dialogue) if total_dialogue > 0 else 0,\n",
    "            'neutral_proportion': (attributes['neutral_dialogue'] / total_dialogue) if total_dialogue > 0 else 0\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "character_arc_df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Save to CSV\n",
    "character_arc_df.to_csv('character_attributes_by_arc.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(character_arc_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
